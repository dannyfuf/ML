# Conformidad Ética
El trabajo fue realizado de manera original por Hans Fluhmann y Danny Fuentes. Hans Fluhmann de tunear los parametros y seleccionar las caracteristicas. Danny Fuentes se encargó de immplementar los modelos y de analizar y manejar la data.

# Instrucciones
- Se entrega un notebook para el procesamiento de los datos, el cual realiza todos los pasos necesarios para producir el csv entregado en kaggle.
- Existe un parametro booleano en las celdas iniciales, la cual permite decidir si el modelo se va a entrenar o no. 
  
## Dependencias:
Se necesitan los siguientes paquetes de python para ejecutar los notebooks

- pandas (as pd)
- numpy (as np)
- StandardScaler
- PCA
- SVC
- train_test_split
- make_multilabel_classification
- MultiOutputClassifier
- RidgeClassifierCV
- LogisticRegression
- roc_auc_score
- RandomForestClassifier
- TruncatedSVD
- matplotlib.pyplot (as plt)
- GridSearchCV

Los paquetes se pueden instalar usando
```bash
pip install <nombre del paquete>
```
